{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IG0xXF7T0x2h"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k75Qsxvc0zzZ"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqXF3IZU00_g"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2MLM03DJ02TK"
   },
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhsS7FZU03uf"
   },
   "source": [
    "# Simple Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XAR-vEvw03hB"
   },
   "outputs": [],
   "source": [
    "# Initialize the webdriver.\n",
    "browser = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SRlMjKmz05uN"
   },
   "outputs": [],
   "source": [
    "# Navigate to a web page.\n",
    "browser.get('https://www.apple.com/mk/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XENkqBtc07ql"
   },
   "outputs": [],
   "source": [
    "# Print the page source code.\n",
    "#print(browser.page_source) --> too long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "j2IK2Ka408sg"
   },
   "outputs": [],
   "source": [
    "# Select an element from the page.\n",
    "element = browser.find_element(By.CLASS_NAME, 'headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ErxN591d09ul"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone 16 Pro\n"
     ]
    }
   ],
   "source": [
    "# Print the element's inner text.\n",
    "print(element.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9CVMKMx0-SY"
   },
   "source": [
    "# Laboratory Exercise - Run Mode (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGHA83FS1Lqk"
   },
   "source": [
    "In this laboratory assignment, the goal is to perform web scraping using **Selenium** on the website https://www.scrapethissite.com/pages/forms/. The task includes the extraction of **hockey team names** and their **wins** and **losses** in the respective **year** for a minimum of 25 hockey teams. Following this data extraction, you will construct a data frame to organize the collected data. Finally, you are expected to generate a histogram to provide a visual representation of the distribution of wins and losses in the year 1990."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMBGzB374oRM"
   },
   "source": [
    "## Hints\n",
    "- To navigate to a specific page with a given URL, use the `browser.get(url)` method.\n",
    "- When selecting a single element, use `browser.find_element`, and for multiple elements, use `browser.find_elements`. Both of these functions take two arguments. The first specifies the attribute used to locate the element on the web page, and the second specifies the value of that attribute.\n",
    "- The `By` class is used to specify which attribute is used to locate elements on a page. These are the various ways the attributes are used to locate elements on a page: `By.ID`, `By.NAME`, `By.TAG_NAME`, `BY.CLASS_NAME`, `By.CSS_SELECTOR`, etc.\n",
    "- For more details, check the documentation (https://selenium-python.readthedocs.io/locating-elements.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOV5K_ji5iQi"
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Naeba0l31AVU"
   },
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "browser.get(\"https://www.scrapethissite.com/pages/forms/?per_page=100\")\n",
    "num_pages = len(browser.find_element(By.CLASS_NAME,\"pagination\").find_elements(By.TAG_NAME,\"li\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PFK34b5R5c0N"
   },
   "outputs": [],
   "source": [
    "items = []\n",
    "for page in range(1,num_pages):\n",
    "    browser.get(f'https://www.scrapethissite.com/pages/forms/?per_page=100&page_num={page}')\n",
    "    teams = browser.find_element(By.CLASS_NAME,\"table\").find_elements(By.CLASS_NAME,\"team\")\n",
    "    for team in teams:\n",
    "        name = team.find_element(By.CLASS_NAME,\"name\").text\n",
    "        year = team.find_element(By.CLASS_NAME,\"year\").text\n",
    "        wins = team.find_element(By.CLASS_NAME,\"wins\").text\n",
    "        losses = team.find_element(By.CLASS_NAME,\"losses\").text\n",
    "        win_pct = team.find_element(By.CLASS_NAME,\"pct\").text\n",
    "        goals_for = team.find_element(By.CLASS_NAME,\"gf\").text\n",
    "        goals_against = team.find_element(By.CLASS_NAME,\"ga\").text\n",
    "        goals_diff = team.find_element(By.CLASS_NAME,\"diff\").text\n",
    "        items.append((name,year,wins,losses,win_pct,goals_for,goals_against,goals_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(items,columns=[\"name\",\"year\",\"wins\",\"losses\",\"win_percentage\",\"goals_for\",\"goals_against\",\"goals_diff\"])\n",
    "df.to_csv(\"csv/teams.csv\")\n",
    "\n",
    "df[\"years\"] = df[\"year\"].astype(int)\n",
    "df[\"wins\"] = df [\"wins\"].astype(int)\n",
    "df[\"losses\"] = df[\"losses\"].astype(int)\n",
    "years_sum = df.groupby(\"year\").agg({\"wins\":\"sum\",\"losses\":\"sum\"})\n",
    "\n",
    "filtered = df[df[\"name\"] == \"Boston Bruins\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCkjUHg75fNe"
   },
   "source": [
    "# Laboratory Exercise - Bonus Task (+ 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1qEBqeW8UJa"
   },
   "source": [
    "In the context of scraping the website https://www.scrapethissite.com/pages/forms/, the additional task involves searching for the hockey team 'Boston Bruins' using the available search field. You will extract the wins and losses data for this team covering the years from 1990 to 2011. After gathering this information, your task is to create a line plot where the wins and losses of the 'Boston Bruins' team are visualized across the years, displaying both trends on the same plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgXk1c4k-5dR"
   },
   "source": [
    "## Hints\n",
    "- To populate an input field (`input_field`) with some `text` use `input_field.send_keys(text)`.\n",
    "- To click on a specific `element` on a web page use `element.click()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXxIi7bv9lPw"
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztX3X1pB5f4j"
   },
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "# I solved everything in the exercise above XD."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
